# â”€â”€ python 3.10+  FINAL VECTORâ€‘MEMORY VERSION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
main.py  (ë°±ì—”ë“œ)
â”€â”€â”€â”€â”€â”€â”€â”€
â— ë²¡í„° DB + Mongo ì— ì €ì¥ëœ **ëª¨ë“  ê³¼ê±° ëŒ€í™”**ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•´ GPT í˜¸ì¶œ
  â€‘ ìµœê·¼ 20ê°œ + ë²¡í„° ìœ ì‚¬ 5ê°œ â†’ í•­ìƒ í¬í•¨
â— ë²¡í„° íšŒìƒ ì‚¬ìš©
â— @ì½”ë”©ë²ˆì—­ê¸° 1â€‘íšŒ í•´ì„ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€
"""
import os, json, asyncio
from datetime import datetime
from functools import partial
from pathlib import Path
from typing import List

from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from openai import OpenAI
from motor.motor_asyncio import AsyncIOMotorClient
import chromadb
from sentence_transformers import SentenceTransformer

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONSTANTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TAG_TRANSLATE = "@ì½”ë”©ë²ˆì—­ê¸°"
SYSTEM_PROMPT = (
    "ë„ˆëŠ” ì‚¬ìš©ìì˜ ê³¼ê±° ë©”ì‹œì§€ì™€ ë³¸ì¸ì˜ ì‘ë‹µì„ í•­ìƒ ë°˜ì˜í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” AI ë¹„ì„œì•¼."
    " ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•´ ì´ì–´ì„œ ë‹µë³€í•´."
)

is_translate_mode = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ INIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv(Path(__file__).parent / ".env")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL   = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
MONGO_URI      = os.getenv("MONGO_URI", "mongodb://localhost:27017")

openai_client = OpenAI(api_key=OPENAI_API_KEY)

mongo      = AsyncIOMotorClient(MONGO_URI).chat
m_col      = mongo.messages
chroma     = chromadb.PersistentClient(path=Path(__file__).parent / "chroma")
collection = chroma.get_or_create_collection("chat_history")
encoder    = SentenceTransformer("intfloat/e5-small-v2")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FASTAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Message(BaseModel):
    type: str
    nickname: str
    message: str
    timestamp: str
    role: str  # "user" | "assistant"
    response_id: str | None = None

clients: List[WebSocket] = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STORAGE HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def save_and_embed(msg: Message):
    res = await m_col.insert_one(msg.dict())
    collection.upsert(
        ids=[str(res.inserted_id)],
        embeddings=[encoder.encode(msg.message).tolist()],
        documents=[msg.message],
        metadatas=[{"nickname": msg.nickname, "role": msg.role}],
    )

async def recent_context(nick: str, k: int = 20) -> list[dict]:
    cur = m_col.find({}).sort("timestamp", -1).limit(k)
    docs = list(reversed(await cur.to_list(None)))
    return [
        {"role": d["role"], "content": d["message"]} for d in docs
    ]

def similar_context(nick: str, query: str, k: int = 5) -> list[dict]:
    res = collection.query(
        query_embeddings=[encoder.encode(query).tolist()],
        n_results=k,
    )
    return [{"role": "assistant", "content": d} for d in res["documents"][0]]

async def gpt_reply(user_text: str, nick: str) -> tuple[str, str]:
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    messages += await recent_context(nick)
    messages += similar_context(nick, user_text)
    messages.append({"role": "user", "content": user_text})

    loop = asyncio.get_running_loop()
    resp = await loop.run_in_executor(
        None,
        partial(
            openai_client.chat.completions.create,
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.7,
            max_tokens=512,
        ),
    )
    txt = resp.choices[0].message.content.strip()
    return txt, resp.id

async def code_translate(code: str) -> str:
    prompt = f"""ë‹¹ì‹ ì€ 'ì½”ë”© ë²ˆì—­ê¸°' ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì•„ë˜ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ì§€ì¼œ ì„¤ëª…í•˜ì„¸ìš”.

1. **ì „ì²´ ê°œìš”** â€¦
2. **ë¼ì¸-ë°”ì´-ë¼ì¸ í•´ì„¤** (â¤ ê¸°í˜¸) â€¦
3. **ë³€ìˆ˜Â·í•¨ìˆ˜ ì´ë¦„ ë²ˆì—­** â€¦
4. **ìš©ì–´ í’€ì´** â€¦
5. **ìµœì¢… íë¦„** â€¦
6. **ì¶”ê°€ í•™ìŠµ í¬ì¸íŠ¸** â€¦:\n```python\n{code}\n```"""
    resp = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
        max_tokens=800,
    )
    return resp.choices[0].message.content.strip(), resp.id

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ REST ENDPOINT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/messages")
async def get_messages():
    docs = await m_col.find().sort("timestamp", 1).to_list(None)
    for d in docs:
        d["_id"] = str(d["_id"])
    return JSONResponse(docs)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WEBSOCKET LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    clients.append(ws)
    global is_translate_mode

    try:
        while True:
            raw = await ws.receive_text()
            data = json.loads(raw)
            data.setdefault("timestamp", datetime.utcnow().isoformat())

            user_msg = Message(**data, role="user")
            await save_and_embed(user_msg)
            await asyncio.gather(*[c.send_text(user_msg.json()) for c in clients])

            # â”€â”€ TAG ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if user_msg.message.strip() == TAG_TRANSLATE:
                is_translate_mode = True
                bot_text = "ğŸ§  ì½”ë”©ì„ ì™„ë²½íˆ í•´ì„í•´ ë“œë¦½ë‹ˆë‹¤! ë‹¤ìŒ ì…ë ¥í•œ ì½”ë“œë¥¼ ì„¤ëª…í• ê²Œìš”."
                resp_id = None
            elif is_translate_mode:
                bot_text, resp_id = await code_translate(user_msg.message)
                is_translate_mode = False
            else:
                bot_text, resp_id = await gpt_reply(user_msg.message, user_msg.nickname)

            bot_msg = Message(
                type="chat", nickname="ChatGPT", message=bot_text,
                timestamp=datetime.utcnow().isoformat(), role="assistant", response_id=resp_id
            )
            await save_and_embed(bot_msg)
            await asyncio.gather(*[c.send_text(bot_msg.json()) for c in clients])

    except WebSocketDisconnect:
        clients.remove(ws)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DEV RUN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("back.main:app", host="127.0.0.1", port=8000, reload=True)
